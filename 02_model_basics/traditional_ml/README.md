

## 基础概念

Q: Overfitting / Underfitting 概念
	A: **过拟合**指模型与数据的匹配程度过高，将训练数据一些正常的起伏、波动、异常值也当作是数据的特征，导致模型对新数据的泛化能力变差。具体的表现为在训练集上表现非常优秀，而在验证集/测试集中表现非常差。

Q: Overfitting 解决
	A: 1) 适量减少特征的数量；2) 添加**正则化项**(Regularization)。正则化，顾名思义，目的是为了降低特征对于预测结果的影响能力。常见的正则化项有L1正则项和L2正则项。

Q: Underfitting 解决
	A: 1) 增加训练轮数；2) 增加模型特征；3) 减少正则项。

Q: Bias / Variance 概念
	A: 偏差 (Bias) 指模型预测结果与真实值的差异程度，描述了模型的拟合能力；方差 (Variance) 指模型面对不同数据集时的差异程度，描述了数据扰动对模型的影响。
	A: 一般来说，越简单模型的偏差越高，方差越低；越复杂模型的偏差越低，方差越高。这同样也对应着模型的过拟合与欠拟合。

Q: Bias / Variance Tradeoff
	A: 权衡偏差与方差的常见方法有**交叉认证**(Cross-Validation)。K折交叉验证的基本方法为：将训练集平均分为 $k$ 份，每次训练取其中一份作为验证集，剩下 $k - 1$ 份作为训练集，重复$k$次，直到每一份小数据集都被作为过验证集。最终的损失为 $k$ 次训练的损失取平均。
	A: 选择合适的模型复杂度. 对于简单数据，使用简单的模型（如线性回归）；对于复杂数据，使用更复杂的模型（如神经网络），但要避免模型过度复杂。
	A: 使用正则化（如 L1 或 L2 正则化）可以控制模型的复杂度，从而减少过拟合。这通过惩罚模型的参数，限制了模型的复杂性，减少了方差。
	A: 数据角度：增加训练数据有助于降低方差，减少过拟合。当数据量增加时，模型能更好地学习到数据的真实模式，而不会仅仅记住训练数据的噪声；去除无关或冗余的特征可以减少方差，从而减少过拟合。同时，保留重要的特征能够减少偏差，提高模型的预测能力。[ref](https://blog.csdn.net/weixin_43221845/article/details/142702155)

## 正则化

Q: L1 正则化
	参数绝对值之和， LASSO, L1 norm, $\Vert \textbf{x}\Vert_1 = \sum_i|x_i|$，特征选择，无法求导，稀疏解，

Q: L2 正则化
	参数平方和平方根，Ridge, $\Vert\textbf{x}\Vert = \sqrt{\sum_i x_i^2}$，更缓和

Q: 为什么 L1 可以用来特征选择？
	参数空间里边，L1 就相当于 一个围绕在原点的菱形，($|L| < C$, 其中 $C$ 是约束半径，跟系数 $\lambda$ 不一样，或者说二者作用相反)，参数优化的时候，需要找到一组参数在这个区域内。在参数调整的过程中，参数更有可能碰到 L1 在轴上的角，所以就比较容易为 0 。而 L2 就是一个圆，更加光滑，所以参数更新比较缓和。


## 指标

Q:  MRR (Mean Reciprocal Rank)。平均倒数排名，是什么
	A：评价搜索算法的效果，结果列表中，第一个结果匹配，分数为1，第二个匹配分数为0.5，第n个匹配分数为1/n，如果没有匹配的句子分数为0。最终的分数为所有得分之和，再求平均。
	$$MRR = \frac{1}{|Q|}\sum_{i = 1}^{|Q|}\frac{1}{rank_i}$$
	$|Q|$ 是 query 个数，$rank$ 是对于第 $i$ 个用户，推荐列表中第一个在 ground-truth结 果中的 item 所在的排列位置。[ref](https://blog.csdn.net/jiangjiang_jian/article/details/108246103)

Q：NDCG (Normalized Discounted cumulative gain)，归一化折损累计增益，是什么
	A：通常是用来衡量和评价搜索结果算法，有两个思想：1) 高关联度的结果比一般关联度的结果更影响最终的指标得分 2) 有高关联度的结果出现在更靠前的位置的时候，指标会越高。
	1. 首先累计增益 **CG (cumulative gain)**，是一个搜素结果相关性分数的总和。
	$$
		CG = \sum_{i = 1}^{p} rel_i
	$$
	其中 $p$ 为指定位置， $rel_i$ 表示这个位置上的相关度。只考虑到了相关性的关联程度，没有考虑到位置的因素。举例：假设搜索“篮球”结果，最理想的结果是：B1、B2、 B3。而出现的结果是 B3、B1、B2的话，CG的值是没有变化的，因此需要下面的DCG。
	2. **DCG， Discounted 的CG**，就是在每一个CG的结果上处以一个折损值。目的就是为了让排名越靠前的结果越能影响最后的结果。假设排序越往后，价值越低。折损权重为 $1 / \log_2 (i + 1)$。
	$$
		\mathrm{DCG}_{\mathrm{p}}=\sum_{i=1}^p \frac{r e l_i}{\log _2(i+1)}=r e l_1+\sum_{i=2}^p \frac{r e l_i}{\log _2(i+1)}
	$$
	当然还有一种比较常用的公式，相关性值为二进制时，即 reli在{0,1}，二者结果是一样的。
	$$
		\mathrm{DCG}_{\mathrm{p}}=\sum_{i=1}^p \frac{2^{rel_i} - 1}{\log _2(i+1)}
	$$
	3. NDCG, **归一化折损累计增益**, Normalized 的DCG，由于搜索结果随着检索词的不同，返回的数量是不一致的，而DCG是一个累加的值，没法针对两个不同的搜索结果进行比较，因此需要归一化处理，这里是处以IDCG。IDCG为理想情况下最大的DCG值。
	$$
		nDCG_p = \frac{DCG_p}{IDCG_p},\quad IDCG_p = \mathrm{DCG}_{\mathrm{p}}=\sum_{i=1}^{|REL|} \frac{2^{rel_i} - 1}{\log _2(i+1)}
	$$
	其中 $|REL|$ 表示结果按照相关性从大到小的顺序排序，取前 $p$ 个结果组成的集合。也就是按照最优的方式对结果进行排序。[ref](https://www.cnblogs.com/by-dream/p/9403984.html)

Q：CTR (Click-Through-Rate) 是什么？
	A: 表示在看过您的广告或非付费商品详情的用户中有多少用户最后点击了广告。点击率可用于评估您的关键字、广告以及非付费商品详情的效果。点击率是指您的广告所获得的点击次数除以其展示次数所得的比值：点击次数 ÷ 展示次数 = 点击率。例如，如果您获得了 5 次点击和 100 次展示，点击率就是 5%。

Q: Precision/Recall/ F1 Score
	二分类问题，有四种分类情况：TP, TN, FP, FN, precision 是在你预测是正确的答案中，你预测对了多少, TP /(TP + FP),  recall 是在所有正确答案中，你预测是正确的预测对了多少，TP / (TP + FN), 前者关注模型预测，后者关心真实数据。
	简单来说，如果你预测的结果是一个列表 L, 这个列表中正确的数量 / 列表长度 就是 precision；这个列表中正确的数量 / 真实数据正确的数量就是 recall；F1 就是二者的调和平均

Q: 混淆矩阵
	TNTPFNFP四个构成的矩阵就是 confusion matrix。有更多分类的混淆矩阵，也是类似形式

Q: macro-$F_1$ vs micro-$F_1$
	macro-F1 就是计算各个 precision 和 各个 recall，然后取平均值得到 macro-P, macro-R，调和平均计算结果。
	micro-F1 就是对元素进行平均，基于总体的混淆矩阵计算 micro-P, R, 然后计算 micro-F1

Q: ROC 曲线和 AUC 面积
	